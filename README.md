# Gestion-des-entrepots-de-donnees-GODET-GUILLARD

## Technologies UtilisÃ©es

### Langage

![Python](https://img.shields.io/badge/Python-3.10.12-blue?logo=python&logoColor=white)


### Cloud & Bases de DonnÃ©es

![MongoDB](https://img.shields.io/badge/MongoDB-5.0-green?logo=mongodb&logoColor=white)


### Outils de Visualisation

![Kibana](https://img.shields.io/badge/Kibana-8.15.0-orange?logo=kibana&logoColor=white)

---

## Objectif du Projet

Ce projet a pour objectif de mettre en place un flux de gestion et dâ€™analyse de donnÃ©es en plusieurs Ã©tapes, depuis leur extraction jusquâ€™Ã  leur visualisation. Le processus est structurÃ© pour automatiser lâ€™acquisition, le traitement et la valorisation des donnÃ©es afin dâ€™en extraire des insights utiles.

## Ã‰tapes du Projet

RÃ©cupÃ©ration des DonnÃ©es via API :
    Les donnÃ©es sont extraites de deux API externes pour collecter les informations nÃ©cessaires. Ces sources apportent des informations sur les belib Ã  Paris ainsi que des donnÃ©es de mÃ©tÃ©o comme la tempÃ©rature, pluviomÃ©trie etc.

Stockage Initial des DonnÃ©es :
    Les donnÃ©es rÃ©cupÃ©rÃ©es sont stockÃ©es dans une base de donnÃ©es MongoDB pour garantir leur persistance et faciliter les traitements ultÃ©rieurs.

Transformation des DonnÃ©es :
    Les donnÃ©es brutes sont ensuite transformÃ©es et nettoyÃ©es Ã  l'aide d'un script pour sâ€™assurer de leur cohÃ©rence, fiabilitÃ© et pertinence pour les analyses. Ce processus peut inclure la normalisation, le filtrage ou l'enrichissement des donnÃ©es.

Restockage des DonnÃ©es TransformÃ©es :
    Les donnÃ©es nettoyÃ©es et enrichies sont stockÃ©es dans un entrepÃ´t de donnÃ©es PosgreSQL, facilitant l'accÃ¨s rapide aux donnÃ©es prÃªtes pour lâ€™analyse.

Visualisation des DonnÃ©es :
    Pour valoriser les donnÃ©es, des visualisations interactives sont crÃ©Ã©es, permettant de gÃ©nÃ©rer des insights visuels et des rapports. Ces visualisations sont essentielles pour lâ€™analyse de tendances et lâ€™aide Ã  la dÃ©cision.


## ğŸ¯ Cibles
- **Utilisateurs de VÃ©los en Libre-Service (Cyclistes)** Les cyclistes pourraient utiliser les donnÃ©es croisÃ©es pour choisir les meilleures pÃ©riodes pour louer un vÃ©lo, en fonction de la mÃ©tÃ©o et de la disponibilitÃ© des stations Belib.
  
- **Gestionnaires des SystÃ¨mes de VÃ©lo (OpÃ©rateurs Belib)** Les opÃ©rateurs peuvent utiliser les donnÃ©es pour mieux gÃ©rer l'implantation et la disponibilitÃ© des vÃ©los dans certaines stations. Par exemple, des stations peuvent Ãªtre rÃ©approvisionnÃ©es en vÃ©los pendant les jours oÃ¹ la mÃ©tÃ©o est favorable Ã  l'utilisation de vÃ©los.
   
- **AutoritÃ©s Locales et Urbanistes** Les autoritÃ©s de la ville de Paris ou des urbanistes pourraient utiliser ces donnÃ©es pour optimiser la planification des infrastructures de transport urbain, amÃ©liorer lâ€™accessibilitÃ© et encourager lâ€™utilisation des vÃ©los.
   
- **Assureurs et SociÃ©tÃ©s de Transport** Les assureurs et les entreprises de transport pourraient utiliser ces informations pour mieux comprendre l'impact de la mÃ©tÃ©o sur la sÃ©curitÃ© des cyclistes et sur la demande de transport en vÃ©lo.
   
- **Chercheurs et Analystes en MobilitÃ© Urbaine** Les chercheurs peuvent analyser les comportements de mobilitÃ© des citadins en fonction de facteurs externes comme la mÃ©tÃ©o. Cela pourrait contribuer Ã  des Ã©tudes sur les modes de transport durables et la maniÃ¨re dont les conditions mÃ©tÃ©orologiques influencent le choix des moyens de transport.
   
- **DÃ©veloppeurs d'Applications et Startups** Des entreprises tech ou des startups dans le domaine de la mobilitÃ© urbaine pourraient utiliser ces donnÃ©es pour crÃ©er des applications ou des services qui optimisent lâ€™utilisation des vÃ©los partagÃ©s en fonction de la mÃ©tÃ©o.
   
- **Touristes et Visiteurs Ã  Paris** Les touristes peuvent profiter d'une application qui leur fournit des conseils sur les conditions de voyage en vÃ©lo Ã  Paris, en prenant en compte la mÃ©tÃ©o.


## Architecture du Projet 

```
.
â”œâ”€â”€ Airflow
â”‚   â””â”€â”€ dags
â”‚   â””â”€â”€ script
â”‚   â””â”€â”€ â””â”€â”€ entrypoint.sh
â”‚   â””â”€â”€ confi_airflow.md
â”‚   â””â”€â”€ docker-compose.yml
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ data_collection
â”‚   â”œâ”€â”€ export_mongodb.csv
â”‚   â”œâ”€â”€ getAPI.py
â”œâ”€â”€ ELK
â”‚   â”œâ”€â”€ config.md
â”‚   â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md

```

## Workflow et SchÃ©ma d'Architecture

1. **Ingestion des DonnÃ©es de Belib (opendata.paris.fr)** :
   - Extraction des informations sur les locations de belib Ã  Paris, envoi des donnÃ©es dans une collection belib sur MongoDB .

2. **Ingestion des informations mÃ©tÃ©o (infoclimat.fr)** :
   - Extraction des prÃ©visions mÃ©tÃ©o sur 7 jours, (donnÃ©es renseignÃ©es toutes les 3 heures)  (tempÃ©rature, pluviomÃ©trie etc) envoie des donnÃ©es dans une collection meteo sur MongoDB.

3. **Traitement des DonnÃ©es** :
   - AgrÃ©gation par la date et stockage sur un fichier CSV

4. **Visualisation et Analyse** :
   - Kibana est utilisÃ© pour crÃ©er des tableaux de bord interactifs, permettant de suivre la conformitÃ© sanitaire et lâ€™expÃ©rience client en temps rÃ©el.


## DÃ©roulement Technique du Projet

### **Ã‰tapes d'installation :**

1. **Cloner le dÃ©pÃ´t :**
   ```bash

   ```

2. **CrÃ©er un environnement virtuel :**
   ```bash
  
   ```

3. **Installer les dÃ©pendances :**
   ```bash
   pip install -r requirements.txt
   ```

**Configurer les variables d'environnement :**
   CrÃ©ez un fichier `.env` et renseignez les informations de connexion MongoDB , OPENAI , le topic kafka , le lien de l'api et Elasticsearch :
   ```env
MONGO_USERNAME="******"
MONGO_PASSWORD="******"
MONGO_DBNAME="*******"
MONGO_URI="*********"
API_URL=https://dgal.opendatasoft.com/api/explore/v2.1/catalog/datasets/export_alimconfiance/records

   ```
  
