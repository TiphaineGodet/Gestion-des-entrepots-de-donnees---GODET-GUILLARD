# Gestion-des-entrepots-de-donnees-GODET-GUILLARD

## Technologies UtilisÃ©es

### Langage

![Python](https://img.shields.io/badge/Python-3.10.12-blue?logo=python&logoColor=white)


### Cloud & Bases de DonnÃ©es

![MongoDB](https://img.shields.io/badge/MongoDB-5.0-green?logo=mongodb&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-14-blue?logo=postgresql&logoColor=white)


### BibliothÃ¨ques de DonnÃ©es & Machine Learning

![Pandas](https://img.shields.io/badge/Pandas-1.5.2-brightgreen?logo=pandas&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-1.21.0-blue?logo=numpy&logoColor=white)

### Outils de Visualisation

![Kibana](https://img.shields.io/badge/Kibana-8.15.0-orange?logo=kibana&logoColor=white)

---

## Objectif du Projet

Ce projet a pour objectif de mettre en place un flux de gestion et dâ€™analyse de donnÃ©es en plusieurs Ã©tapes, depuis leur extraction jusquâ€™Ã  leur visualisation. Le processus est structurÃ© pour automatiser lâ€™acquisition, le traitement et la valorisation des donnÃ©es afin dâ€™en extraire des insights utiles.

## Ã‰tapes du Projet

RÃ©cupÃ©ration des DonnÃ©es via API :
    Les donnÃ©es sont extraites de deux API externes pour collecter les informations nÃ©cessaires. Ces sources apportent des informations sur les belib Ã  Paris ainsi que des donnÃ©es de mÃ©tÃ©o comme la tempÃ©rature, pluviomÃ©trie etc.

Stockage Initial des DonnÃ©es :
    Les donnÃ©es rÃ©cupÃ©rÃ©es sont stockÃ©es dans une base de donnÃ©es MongoDB pour garantir leur persistance et faciliter les traitements ultÃ©rieurs.

Transformation des DonnÃ©es :
    Les donnÃ©es brutes sont ensuite transformÃ©es et nettoyÃ©es Ã  l'aide d'un script pour sâ€™assurer de leur cohÃ©rence, fiabilitÃ© et pertinence pour les analyses. Ce processus peut inclure la normalisation, le filtrage ou l'enrichissement des donnÃ©es.

Restockage des DonnÃ©es TransformÃ©es :
    Les donnÃ©es nettoyÃ©es et enrichies sont stockÃ©es dans un entrepÃ´t de donnÃ©es PosgreSQL, facilitant l'accÃ¨s rapide aux donnÃ©es prÃªtes pour lâ€™analyse.

Visualisation des DonnÃ©es :
    Pour valoriser les donnÃ©es, des visualisations interactives sont crÃ©Ã©es, permettant de gÃ©nÃ©rer des insights visuels et des rapports. Ces visualisations sont essentielles pour lâ€™analyse de tendances et lâ€™aide Ã  la dÃ©cision.


## ðŸŽ¯ Cibles
- **Utilisateurs de VÃ©los en Libre-Service (Cyclistes)** Les cyclistes pourraient utiliser les donnÃ©es croisÃ©es pour choisir les meilleures pÃ©riodes pour louer un vÃ©lo, en fonction de la mÃ©tÃ©o et de la disponibilitÃ© des stations Belib.
  
- **Gestionnaires des SystÃ¨mes de VÃ©lo (OpÃ©rateurs Belib)** Les opÃ©rateurs peuvent utiliser les donnÃ©es pour mieux gÃ©rer l'implantation et la disponibilitÃ© des vÃ©los dans certaines stations. Par exemple, des stations peuvent Ãªtre rÃ©approvisionnÃ©es en vÃ©los pendant les jours oÃ¹ la mÃ©tÃ©o est favorable Ã  l'utilisation de vÃ©los.
   
- **AutoritÃ©s Locales et Urbanistes** Les autoritÃ©s de la ville de Paris ou des urbanistes pourraient utiliser ces donnÃ©es pour optimiser la planification des infrastructures de transport urbain, amÃ©liorer lâ€™accessibilitÃ© et encourager lâ€™utilisation des vÃ©los.
   
- **Assureurs et SociÃ©tÃ©s de Transport** Les assureurs et les entreprises de transport pourraient utiliser ces informations pour mieux comprendre l'impact de la mÃ©tÃ©o sur la sÃ©curitÃ© des cyclistes et sur la demande de transport en vÃ©lo.
   
- **Chercheurs et Analystes en MobilitÃ© Urbaine** Les chercheurs peuvent analyser les comportements de mobilitÃ© des citadins en fonction de facteurs externes comme la mÃ©tÃ©o. Cela pourrait contribuer Ã  des Ã©tudes sur les modes de transport durables et la maniÃ¨re dont les conditions mÃ©tÃ©orologiques influencent le choix des moyens de transport.
   
- **DÃ©veloppeurs d'Applications et Startups** Des entreprises tech ou des startups dans le domaine de la mobilitÃ© urbaine pourraient utiliser ces donnÃ©es pour crÃ©er des applications ou des services qui optimisent lâ€™utilisation des vÃ©los partagÃ©s en fonction de la mÃ©tÃ©o.
   
- **Touristes et Visiteurs Ã  Paris** Les touristes peuvent profiter d'une application qui leur fournit des conseils sur les conditions de voyage en vÃ©lo Ã  Paris, en prenant en compte la mÃ©tÃ©o.


## Architecture du Projet 

```
.
â”œâ”€â”€ data
â”‚   â””â”€â”€ kafka_messages.csv
â”œâ”€â”€ data-ingestion-kedro
â”‚   â”œâ”€â”€ conf
â”‚   â”œâ”€â”€ data
â”‚   â”œâ”€â”€ notebooks
â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ session_store.db
â”‚   â”œâ”€â”€ src
â”‚   â””â”€â”€ tests
â”œâ”€â”€ docs
â”‚   â””â”€â”€ realtime_restaurant_insights_project_description.pdf.pdf
â”œâ”€â”€ ELK
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ import_to_elasticsearch.py
â”œâ”€â”€ ENV
â”‚   â”œâ”€â”€ bin
â”‚   â”œâ”€â”€ etc
â”‚   â”œâ”€â”€ include
â”‚   â”œâ”€â”€ lib
â”‚   â”œâ”€â”€ lib64 -> lib
â”‚   â”œâ”€â”€ pyvenv.cfg
â”‚   â””â”€â”€ share
â”œâ”€â”€ image-1.png
â”œâ”€â”€ image-2.png
â”œâ”€â”€ image-3.png
â”œâ”€â”€ image-4.png
â”œâ”€â”€ image.png
â”œâ”€â”€ kafka
â”œâ”€â”€ kedro-airflow
â”‚   â”œâ”€â”€ dags
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ script
â”œâ”€â”€ notebook
â”‚   â””â”€â”€ EDA.ipynb
â”œâ”€â”€ README.md
â”œâ”€â”€ script
â”‚   â”œâ”€â”€ getApi_Alim.py
â”‚   â””â”€â”€ preprocessing.py
â”œâ”€â”€ sentiment_analysis_kafka
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ sentiment_analysis.py
â””â”€â”€ spark
    â”œâ”€â”€ kafka_to_spark.py
    â””â”€â”€ script
```

## Workflow et SchÃ©ma d'Architecture

1. **Ingestion des DonnÃ©es de Belib (opendata.paris.fr)** :
   - Extraction des informations sur les locations de belib Ã  Paris, envoi des donnÃ©es dans une collection belib sur MongoDB .

2. **Ingestion des informations mÃ©tÃ©o (infoclimat.fr)** :
   - Extraction des prÃ©visions mÃ©tÃ©o sur 7 jours, (donnÃ©es renseignÃ©es toutes les 3 heures)  (tempÃ©rature, pluviomÃ©trie etc) envoie des donnÃ©es dans une collection meteo sur MongoDB.

3. **Traitement des DonnÃ©es** :
   

4. **Indexation et Stockage** :
   - Les donnÃ©es nettoyÃ©es sont stockÃ©es dans PosgreSQL, indexÃ©es par la date.

5. **Visualisation et Analyse** :
   - Kibana est utilisÃ© pour crÃ©er des tableaux de bord interactifs, permettant de suivre la conformitÃ© sanitaire et lâ€™expÃ©rience client en temps rÃ©el.


## DÃ©roulement Technique du Projet

### **Ã‰tapes d'installation :**

1. **Cloner le dÃ©pÃ´t :**
   ```bash

   ```

2. **CrÃ©er un environnement virtuel :**
   ```bash
  
   ```

3. **Installer les dÃ©pendances :**
   ```bash
   pip install -r requirements.txt
   ```

**Configurer les variables d'environnement :**
   CrÃ©ez un fichier `.env` et renseignez les informations de connexion MongoDB , OPENAI , le topic kafka , le lien de l'api et Elasticsearch :
   ```env
MONGO_USERNAME="******"
MONGO_PASSWORD="******"
MONGO_DBNAME="*******"
MONGO_URI="*********"
API_URL=https://dgal.opendatasoft.com/api/explore/v2.1/catalog/datasets/export_alimconfiance/records

   ```
  
